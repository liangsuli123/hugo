---
title: "使用线程池、进程池、协程向多个url并发获取页面数据比较"
date: 2018-08-08T14:26:00+08:00
draft: false
tags: ["网络协议"]
slug: "B7"
---
```
特点：

　　　　　　1．进程：启用进程非常浪费资源
　　　　　　2．线程：线程多，并且在阻塞过程中无法执行其他任务
　　　　　　3．协程：gevent只用起一个线程，当请求发出去后gevent就不管,永远就只有一个线程工作，谁先回来先处理

　　1、使用for循环串行拿取页面数据（第四：性能最差）


复制代码
import requests
url_list = [
    'https://www.baidu.com',
    'http://dig.chouti.com/',
]

for url in url_list:
    result = requests.get(url)
    print(result.text)
复制代码
　　2、进程池实现并发（第三）

　　　　缺点：启用进程非常浪费资源


复制代码
import requests
from concurrent.futures import ProcessPoolExecutor

def fetch_request(url):
    result = requests.get(url)
    print(result.text)

url_list = [
    'https://www.baidu.com',
    'https://www.google.com/',         #google页面会卡住，知道页面超时后这个进程才结束
    'http://dig.chouti.com/',          #chouti页面内容会直接返回，不会等待Google页面的返回
]

if __name__ == '__main__':
    pool = ProcessPoolExecutor(10)        # 创建线程池
    for url in url_list:
        pool.submit(fetch_request,url)    # 去线程池中获取一个进程，进程去执行fetch_request方法
    pool.shutdown(False)
复制代码
　　3、线程池实现并发（第二）

　　　　　　缺点： 创建一个新线程将消耗大量的计算资源，并且在阻塞过程中无法执行其他任务。
　　　　　　例： 比如线程池中10个线程同时去10个url获取数据，当数据还没来时这些线程全部都在等待，不做事。


复制代码
import requests
from concurrent.futures import ThreadPoolExecutor

def fetch_request(url):
    result = requests.get(url)
    print(result.text)

url_list = [
    'https://www.baidu.com',
    'https://www.google.com/',         #google页面会卡住，知道页面超时后这个进程才结束
    'http://dig.chouti.com/',          #chouti页面内容会直接返回，不会等待Google页面的返回
]

pool = ThreadPoolExecutor(10)            # 创建一个线程池，最多开10个线程
for url in url_list:
    pool.submit(fetch_request,url)       # 去线程池中获取一个线程，线程去执行fetch_request方法

pool.shutdown(True)                      # 主线程自己关闭，让子线程自己拿任务执行
复制代码

复制代码
from concurrent.futures import ThreadPoolExecutor
import requests

def fetch_async(url):
    response = requests.get(url)
    return response.text

def callback(future):
    print(future.result())

url_list = ['http://www.github.com', 'http://www.bing.com']
pool = ThreadPoolExecutor(5)
for url in url_list:
    v = pool.submit(fetch_async, url)
    v.add_done_callback(callback)
pool.shutdown(wait=True)
复制代码
　　4、协程：微线程实现异步（第一：性能最好）

　　　　　　特点 ：gevent只用起一个线程，当请求发出去后gevent就不管,永远就只有一个线程工作，谁先回来先处理


复制代码
import gevent
import requests
from gevent import monkey

monkey.patch_all()

# 这些请求谁先回来就先处理谁
def fetch_async(method, url, req_kwargs):
    response = requests.request(method=method, url=url, **req_kwargs)
    print(response.url, response.content)

# ##### 发送请求 #####
gevent.joinall([
    gevent.spawn(fetch_async, method='get', url='https://www.python.org/', req_kwargs={}),
    gevent.spawn(fetch_async, method='get', url='https://www.google.com/', req_kwargs={}),
    gevent.spawn(fetch_async, method='get', url='https://github.com/', req_kwargs={}),
])
```
