---
title: "Python进程池和线程池"
date: 2018-08-05T14:26:00+08:00
draft: false
tags: ["网络协议"]
slug: "B6"
---

```
1、简介 参考官网

　　　　　　1、Python标准库为我们提供了threading和multiprocessing模块编写相应的多线程/多进程代码
　　　　　　2、但是当项目达到一定的规模，频繁创建/销毁进程或者线程是非常消耗资源的，这个时候我们就要编写自己的线程池/进程池，以空间换时间。
　　　　　　3、但从Python3.2开始，标准库为我们提供了concurrent.futures模块，它提供了ThreadPoolExecutor和ProcessPoolExecutor两个类，
　　　　　　4、实现了对threading和multiprocessing的进一步抽象，对编写线程池/进程池提供了直接的支持。

　　2、Executor和Future

　　　　1. Executor

　　　　　　1. concurrent.futures模块的基础是Exectuor，Executor是一个抽象类，它不能被直接使用。
　　　　　　2. 但是它提供的两个子类ThreadPoolExecutor和ProcessPoolExecutor却是非常有用
　　　　　　3. 我们可以将相应的tasks直接放入线程池/进程池，不需要维护Queue来操心死锁的问题，线程池/进程池会自动帮我们调度。

　　　　2. Future

　　　　　　1. Future你可以把它理解为一个在未来完成的操作，这是异步编程的基础，
　　　　　　2. 传统编程模式下比如我们操作queue.get的时候，在等待返回结果之前会产生阻塞，cpu不能让出来做其他事情，
　　　　　　3. 而Future的引入帮助我们在等待的这段时间可以完成其他的操作。

　　3、ThreadPoolExecutor(线程池)


复制代码
from concurrent.futures import ThreadPoolExecutor
import time
def return_future_result(message):
    time.sleep(2)
    return message
pool = ThreadPoolExecutor(max_workers=2)                 # 创建一个最大可容纳2个task的线程池
future1 = pool.submit(return_future_result, ("hello"))  # 往线程池里面加入一个task
future2 = pool.submit(return_future_result, ("world"))  # 往线程池里面加入一个task

print(future1.done())      # 判断task1是否结束
time.sleep(3)
print(future2.done())      # 判断task2是否结束
print(future1.result())    # 查看task1返回的结果
print(future2.result())    # 查看task2返回的结果

# 运行结果：
# False   # 这个False与下面的True会等待3秒
# True    # 后面三个输出都是一起打出来的
# hello
# world
复制代码

复制代码
import concurrent.futures
import urllib.request
URLS = ['http://httpbin.org', 'http://example.com/', 'https://api.github.com/']
def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()

# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
    # Start the load operations and mark each future with its URL
    # future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}   # 这一句相当于下面for循环获取的字典
    future_to_url = {}
    for url in URLS:
        future_to_url[executor.submit(load_url,url,60)] = url      # {'future对象':'url'}   future对象作为key，url作为value
    for future in concurrent.futures.as_completed(future_to_url): # as_completed返回已经有返回结果的future对象
        url = future_to_url[future]                                # 通过future对象获取对应的url
        try:
            data = future.result()                                 # 获取future对象的返回结果
        except Exception as exc:
            print('%r generated an exception: %s' % (url, exc))
        else:
            print('%r page is %d bytes' % (url, len(data)))
复制代码

复制代码
from concurrent.futures import ThreadPoolExecutor

# 创建线程池
executor = ThreadPoolExecutor(10)

def test_function(num1,num2):
    return "%s + %s = %s"%(num1,num2,num1+num2)
result_iterators = executor.map(test_function,[1,2,3],[5,6,7])

for result in result_iterators:
    print(result)

# 1 + 5 = 6
# 2 + 6 = 8
# 3 + 7 = 10
复制代码

复制代码
import concurrent.futures
import urllib.request

URLS = ['http://httpbin.org', 'http://example.com/', 'https://api.github.com/']

def load_url(url):
    with urllib.request.urlopen(url, timeout=60) as conn:
        return conn.read()

# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
    future_dic = {}
    for url, data in zip(URLS, executor.map(load_url, URLS)):
        print('%r page is %d bytes' % (url, len(data)))
        future_dic[url] = data     # {'url':'执行结果'}   url作为key，执行结果作为value

# 'http://httpbin.org' page is 13011 bytes
# 'http://example.com/' page is 1270 bytes
# 'https://api.github.com/' page is 2039 bytes

```

