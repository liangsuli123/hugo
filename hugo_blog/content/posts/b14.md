---
title: "Celery介绍"
date: 2018-09-08T14:26:00+08:00
draft: false
tags: ["网络协议"]
slug: "B14"
---

```
参考博客：http://www.cnblogs.com/alex3714/p/6351797.html

　　1、celery应用举例

　　　　　　1、Celery 是一个 基于python开发的分布式异步消息任务队列，通过它可以轻松的实现任务的异步处理，
　　　　　　 　　 如果你的业务场景中需要用到异步任务，就可以考虑使用celery

　　　　　　2、你想对100台机器执行一条批量命令，可能会花很长时间 ，但你不想让你的程序等着结果返回，而是给你返回 一个任务ID,
　　　　　　　　你过一段时间只需要拿着这个任务id就可以拿到任务执行结果， 在任务执行ing进行时，你可以继续做其它的事情

　　　　　　3、Celery 在执行任务时需要通过一个消息中间件来接收和发送任务消息，以及存储任务结果， 一般使用rabbitMQ or Redis

　　2、Celery有以下优点

　　　　　　1、简单：一单熟悉了celery的工作流程后，配置和使用还是比较简单的

　　　　　　2、高可用：当任务执行失败或执行过程中发生连接中断，celery 会自动尝试重新执行任务

　　　　　　3、快速：一个单进程的celery每分钟可处理上百万个任务

　　　　　　4、灵活： 几乎celery的各个组件都可以被扩展及自定制

　　3、Celery基本工作流程图

　　　　　　

1.2 celery简单使用     返回顶部
 　　1、安装

　　　　　　1.  安装celery： pip3 install celery             # ln -s /usr/local/python3/bin/celery /bin/celery

　　　　　　2.  安装redis

 　　2、创建tasks.py文件进行验证


复制代码
from celery import Celery
import time

app = Celery('TASK',
             broker='redis://localhost',        
             backend='redis://localhost')

@app.task
def add(x, y):
   print("running..add.", x, y)
   return x + y

@app.task
def minus(x, y):
   time.sleep(60)
   print("running..minus.", x, y)
   return x - y
复制代码
　　　　1、启动Celery Worker来开始监听并执行任务

　　　　　　　　celery -A tasks worker --loglevel=info            # tasks是tasks.py文件：必须在tasks.py所在目录下执行

　　　　2、调用任务：再打开两个终端，进行命令行模式，调用任务

　　　　　　　　 >>> import tasks

　　　　　　　　>>> import tasks

　　　　　　　　>>> t2 = tasks.minus.delay(9,11)

　　　　　　　　#然后在另一个终端重复上面步骤执行

　　　　　　　　>>> t1 = tasks.add.delay(3,4)

　　　　　　　　>>> t1.get()                                                   #由于t2执行sleep了3s所以t1.get()需要等待

　　3、celery其他命令

　　　　　　>>> t.ready()                                                  #返回true证明可以执行，不必等待

　　　　　　>>> t.get(timeout=1)                                      #如果1秒不返回结果就超时,避免一直等待

　　　　　　>>> t.get(propagate=False)                          #如果执行的代码错误只会打印错误信息

　　　　　　>>> t.traceback                                             #打印异常详细结果
```
