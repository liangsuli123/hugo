---
title: "线程，进程应用场景"
date: 2018-07-08T14:26:00+08:00
draft: false
tags: ["网络协议"]
slug: "B4"
---
```
1、多线程和多进程各自应用场景

　　　　　　1. I/O操作不占用CPU（从硬盘，网路读入数据等）

　　　　　　2. 计算占用CPU，这种情况最好不用多线程

　　　　　　3. python多线程不适合CPU密集型的任务，适合I/O密集型的任务

　　　　　　4. python的多进程适合CPU密集型任务

　　2、一次性起多个进程，并在进程中调用线程


复制代码
import multiprocessing,time,threading

#3 被多线程调用的函数
def thread_run():
    print(threading.get_ident())   #打印线程id号
    time.sleep(2)

#2 被多进程调用的函数，以及在这个函数中起一个进程
def run(name):
    time.sleep(2)
    print("hello",name)
    t = threading.Thread(target=thread_run,)  #在进程调用的函数中启用一个线程
    t.start()

#1 一次性启动多个进程
if __name__ == '__main__':
    for i in range(10):
        p = multiprocessing.Process(target=run,args=('bob %s'%i,)) #启用一个多线程
        p.start()
复制代码
　　3、进程间互相访问数据的三种方法

　　　　注：不同进程间内存是不共享的，所以互相之间不能访问对方数据

　　　　1. 在父进程中定义队列q，使用父进程启用一个子进程，子进程中无法操作父进程的q


复制代码
from multiprocessing import Process
import queue
import threading
def f():
    q.put([42, None, 'hello'])
 
if __name__ == '__main__':
    q = queue.Queue()              #1 在父进程中定义一个队列实例q
    # p = threading.Thread(target=f,)    #在线程程中就可以相互访问，线程中内存共享
    p = Process(target=f,)        #2 在父进程中起一个子进程 p，在子进程中使用父进程的q会报错
    p.start()
    print(q.get())
    p.join()
复制代码
　　　　2. 法1:  利用Queues实现父进程到子进程（或子进程间）的数据传递

　　　　　　　　1. 我们以前学的queue是线程queue.Queue()只有在同一个进程的线程间才能访问
　　　　　　　　2. 如果两个进程间想要通信必须要使用进程Queue，用法和多线程的相同
　　　　　　　　3. queue.Queue()是线程q不可以传递给子进程，但是Queue是进程q，父进程会将进程q克隆了一份给子进程
　　　　　　　　4.既然是两个q为什么在子进程中在q中放入一个数据在父进程中可以取出来呢？ 其实原因是这样的：
　　　　　　　　　　1）子进程向q中放入数据的时候，用pickle序列化将数据放到一个中间地方（翻译），翻译又把子进程放
　　　　　　　　　　      入的数据用pickle反序列化给父进程，父进程就可以访问这个q了，这样就实现了进程间的数据通信了
　　　　　　　　　　2）	在多线程中两个线程可以修改同一份数据，而Queue仅仅实现了进程间的数据传递


复制代码
from multiprocessing import Process, Queue

def f(qq):  # 将符进程中的q传递过来叫qq
    qq.put([42, None, 'hello'])  # 此时子进程就可以使用符进程中的q

if __name__ == '__main__':
    q = Queue()  # 使用Queue()在父进程中定义一个队列实例q
    p = Process(target=f, args=(q,))  # 在父进程中起一个子进程 p，将父进程刚定义的q传递给子进程p
    p.start()
    print(q.get())
    p.join()

# 运行结果： [42, None, 'hello']
复制代码
　　　　3. 法2:  使用管道pipe实现两个进程间数据传递

　　　　　　　　说明：其实pip实现进程间通信就好像一条电话线一样，一个在电话线这头发送，一个在电话线那头接收


复制代码
from multiprocessing import Process, Pipe

def f(conn):
    conn.send([42, None, 'hello'])  # 3 子进程发送数据，就像socket一样
    print("son process recv:", conn.recv())
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    # 1 生成一个管道实例，实例一生成就会生成两个返回对象，一个是管道这头，一个是管道那头
    p = Process(target=f, args=(child_conn,))  # 2 启动一个子进程将管道其中一头传递给子进程
    p.start()
    print(parent_conn.recv())  # 4 父进程收消息 # prints "[42, None, 'hello']"
    parent_conn.send('i am parent process')
    p.join()

# 运行结果：
# [42, None, 'hello']
# son process recv: i am parent process
复制代码
　　　　4.法3:  Managers实现很多进程间数据共享

　　　　　　　　说明:  manager实质和Queue一样，启用是个线程其实就是将字典或者列表copy十份


复制代码
from multiprocessing import Process, Manager
import os

def f(d, l):
    d[1] = '1'  # 是个进程对字典放入的是同一个值，所以看上去效果不明显
    l.append(os.getpid())  # 将这是个进程的进程id放入列表中


if __name__ == '__main__':
    with Manager() as manager:  # 1 将Manager()赋值给manager
        d = manager.dict()  # 2 定义一个可以在多个进程间可以共享的字典
        l = manager.list(range(5))  # 3 定义一个可以在多个进程间可以共享的列表，默认写五个数据
        p_list = []
        for i in range(10):  # 生成是个进程
            p = Process(target=f, args=(d, l))  # 将刚刚生成的可共享字典和列表传递给子进程
            p.start()
            p_list.append(p)
        for res in p_list:
            res.join()
        print(d)
        print(l)
复制代码
　　4、进程之间需要锁的原因

　　　　　　说明：虽然每个进程是独立运行的，但是他们共享同一块屏幕，如果大家都在屏幕打数据就会打乱了


复制代码
from multiprocessing import Process, Lock
def f(l, i):
    l.acquire()                     #一个进程要打印数据时先锁定
    print('hello world', i)
    l.release()                     #打印完毕后就释放这把锁
if __name__ == '__main__':
    lock = Lock()                   #先生成一把锁
    for num in range(5):
        Process(target=f, args=(lock, num)).start()

# 运行结果：
# hello world 4
# hello world 0
# hello world 2
# hello world 3
# hello world 1
复制代码
　　5、进程池

　　　　　　1. 进程池的作用就是限制同一时间可以启动进程的=数量
　　　　　　2. 进程池内部维护一个进程序列，当使用时，则去进程池中获取一个进程，如果进程池序列中没有可供使用的进
　　　　　　   ，那么程序就会等待，直到进程池中有可用进程为止。
　　　　　　3. 进程池中有两个方法：
　　　　　　         1）apply：	多个进程异步执行，一个一个的执行
　　　　　　         2）apply_async：	多个进程同步执行，同时执行多个进程


复制代码
from  multiprocessing import Process,Pool
import time,os
def foo(i):
    time.sleep(2)
    print("in the process",os.getpid()) #打印子进程的pid
    return i+100

def call(arg):
    print('-->exec done:',arg,os.getpid())

if __name__ == '__main__':
    pool = Pool(3)                      #进程池最多允许5个进程放入进程池
    print("主进程pid：",os.getpid())     #打印父进程的pid
    for i in range(10):
        #用法1 callback作用是指定只有当Foo运行结束后就执行callback调用的函数,父进程调用的callback函数
        pool.apply_async(func=foo, args=(i,),callback=call)

        #用法2 串行 启动进程不在用Process而是直接用pool.apply()
        # pool.apply(func=foo, args=(i,))

    print('end')
    pool.close()    #关闭pool
    pool.join()     #进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。
```